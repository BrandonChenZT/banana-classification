{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-28T07:53:34.733413Z","iopub.status.busy":"2024-04-28T07:53:34.732668Z","iopub.status.idle":"2024-04-28T07:56:33.686210Z","shell.execute_reply":"2024-04-28T07:56:33.685355Z","shell.execute_reply.started":"2024-04-28T07:53:34.733383Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/15], Loss: 0.8170, Accuracy: 68.77%\n","Epoch [2/15], Loss: 0.4622, Accuracy: 82.55%\n","Epoch [3/15], Loss: 0.3780, Accuracy: 86.35%\n","Epoch [4/15], Loss: 0.2738, Accuracy: 91.14%\n","Epoch [5/15], Loss: 0.1428, Accuracy: 95.47%\n","Epoch [6/15], Loss: 0.1786, Accuracy: 93.77%\n","Epoch [7/15], Loss: 0.2272, Accuracy: 92.65%\n","Epoch [8/15], Loss: 0.0749, Accuracy: 97.64%\n","Epoch [9/15], Loss: 0.0552, Accuracy: 98.16%\n","Epoch [10/15], Loss: 0.0489, Accuracy: 98.62%\n","Epoch [11/15], Loss: 0.1043, Accuracy: 97.11%\n","Epoch [12/15], Loss: 0.0556, Accuracy: 98.49%\n","Epoch [13/15], Loss: 0.0259, Accuracy: 99.15%\n","Epoch [14/15], Loss: 0.0810, Accuracy: 97.44%\n","Epoch [15/15], Loss: 0.1162, Accuracy: 95.93%\n"]}],"source":["import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","from PIL import Image\n","import os\n","\n","# 数据预处理\n","import os\n","\n","class BananaDataset(Dataset):\n","    def __init__(self, csv_file, base_dir, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.base_dir = \"/kaggle/input/banana-classification/valid\"  # 图片的基目录\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image_filename = self.data.iloc[idx, 0]\n","        image_path = os.path.join(self.base_dir, image_filename)  # 构造绝对路径\n","#         print(f\"Trying to open image: {image_path}\")  # 打印图片路径\n","        image = Image.open(image_path)\n","        label = self.data.iloc[idx, 1:].values.astype(float)  # 将标签转换为浮点数\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, torch.tensor(label, dtype=torch.float32)\n","\n","# 转换\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 数据集和数据加载器\n","dataset = BananaDataset(csv_file='/kaggle/input/banana-classification/valid/_classes.csv',  base_dir=\"/kaggle/input/banana-classification/valid\",transform=transform)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","\n","# 模型\n","model = torchvision.models.resnet50(pretrained=True)\n","model.fc = torch.nn.Linear(model.fc.in_features, 6)  # 修改最后一层\n","# 冻结除第3层和第4层以及全连接层之外的所有层\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# 仅第3层和第4层以及全连接层可训练\n","for param in model.layer3.parameters():\n","    param.requires_grad = True\n","for param in model.layer4.parameters():\n","    param.requires_grad = True\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","\n","# 损失函数和优化器\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 15 # 示例周期数\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for images, labels in dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # 前向传播\n","        outputs = model(images)\n","        loss = criterion(outputs, labels.argmax(dim=1))\n","\n","        # 反向传播和优化\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 计算损失和准确率\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels.argmax(dim=1)).sum().item()\n","\n","    # 打印每个周期的损失和准确率\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}, Accuracy: {100 * correct/total:.2f}%')\n","\n","    # 保存模型\n","    torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T07:59:12.718932Z","iopub.status.busy":"2024-04-28T07:59:12.718088Z","iopub.status.idle":"2024-04-28T07:59:21.484722Z","shell.execute_reply":"2024-04-28T07:59:21.483807Z","shell.execute_reply.started":"2024-04-28T07:59:12.718902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model on the test images: 98.68766404199475%\n"]}],"source":["# 测试模型的函数\n","def test_model(model, test_loader, device):\n","    model.eval()  # 设置模型为评估模式\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():  # 在测试阶段不计算梯度\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels.argmax(dim=1)).sum().item()\n","\n","    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n","\n","# 创建测试数据加载器（确保使用正确的数据集和数据变换）\n","test_dataloader = DataLoader(BananaDataset(csv_file='/kaggle/input/banana-classification/valid/_classes.csv', base_dir=\"/kaggle/input/banana-classification/valid\", transform=transform), batch_size=32, shuffle=False)\n","\n","# 加载最后一个保存的模型并测试\n","model.load_state_dict(torch.load(f'model_epoch_{10}.pth'))\n","model.to(device)\n","test_model(model, test_dataloader, device)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4857814,"sourceId":8200303,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
