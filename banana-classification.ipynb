{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8200303,"sourceType":"datasetVersion","datasetId":4857814}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nfrom PIL import Image\nimport os\n\n# 数据预处理\nimport os\n\nclass BananaDataset(Dataset):\n    def __init__(self, csv_file, base_dir, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.base_dir = \"/kaggle/input/banana-classification/valid\"  # 图片的基目录\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_filename = self.data.iloc[idx, 0]\n        image_path = os.path.join(self.base_dir, image_filename)  # 构造绝对路径\n#         print(f\"Trying to open image: {image_path}\")  # 打印图片路径\n        image = Image.open(image_path)\n        label = self.data.iloc[idx, 1:].values.astype(float)  # 将标签转换为浮点数\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(label, dtype=torch.float32)\n\n# 转换\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# 数据集和数据加载器\ndataset = BananaDataset(csv_file='/kaggle/input/banana-classification/valid/_classes.csv',  base_dir=\"/kaggle/input/banana-classification/valid\",transform=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# 模型\nmodel = torchvision.models.resnet50(pretrained=True)\nmodel.fc = torch.nn.Linear(model.fc.in_features, 6)  # 修改最后一层\n# 冻结除第3层和第4层以及全连接层之外的所有层\nfor param in model.parameters():\n    param.requires_grad = False\n\n# 仅第3层和第4层以及全连接层可训练\nfor param in model.layer3.parameters():\n    param.requires_grad = True\nfor param in model.layer4.parameters():\n    param.requires_grad = True\nfor param in model.fc.parameters():\n    param.requires_grad = True\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\n# 损失函数和优化器\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 15 # 示例周期数\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # 前向传播\n        outputs = model(images)\n        loss = criterion(outputs, labels.argmax(dim=1))\n\n        # 反向传播和优化\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # 计算损失和准确率\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.argmax(dim=1)).sum().item()\n\n    # 打印每个周期的损失和准确率\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}, Accuracy: {100 * correct/total:.2f}%')\n\n    # 保存模型\n    torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T07:53:34.732668Z","iopub.execute_input":"2024-04-28T07:53:34.733413Z","iopub.status.idle":"2024-04-28T07:56:33.686210Z","shell.execute_reply.started":"2024-04-28T07:53:34.733383Z","shell.execute_reply":"2024-04-28T07:56:33.685355Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15], Loss: 0.8170, Accuracy: 68.77%\nEpoch [2/15], Loss: 0.4622, Accuracy: 82.55%\nEpoch [3/15], Loss: 0.3780, Accuracy: 86.35%\nEpoch [4/15], Loss: 0.2738, Accuracy: 91.14%\nEpoch [5/15], Loss: 0.1428, Accuracy: 95.47%\nEpoch [6/15], Loss: 0.1786, Accuracy: 93.77%\nEpoch [7/15], Loss: 0.2272, Accuracy: 92.65%\nEpoch [8/15], Loss: 0.0749, Accuracy: 97.64%\nEpoch [9/15], Loss: 0.0552, Accuracy: 98.16%\nEpoch [10/15], Loss: 0.0489, Accuracy: 98.62%\nEpoch [11/15], Loss: 0.1043, Accuracy: 97.11%\nEpoch [12/15], Loss: 0.0556, Accuracy: 98.49%\nEpoch [13/15], Loss: 0.0259, Accuracy: 99.15%\nEpoch [14/15], Loss: 0.0810, Accuracy: 97.44%\nEpoch [15/15], Loss: 0.1162, Accuracy: 95.93%\n","output_type":"stream"}]},{"cell_type":"code","source":"# 测试模型的函数\ndef test_model(model, test_loader, device):\n    model.eval()  # 设置模型为评估模式\n    correct = 0\n    total = 0\n    with torch.no_grad():  # 在测试阶段不计算梯度\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels.argmax(dim=1)).sum().item()\n\n    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n\n# 创建测试数据加载器（确保使用正确的数据集和数据变换）\ntest_dataloader = DataLoader(BananaDataset(csv_file='/kaggle/input/banana-classification/valid/_classes.csv', base_dir=\"/kaggle/input/banana-classification/valid\", transform=transform), batch_size=32, shuffle=False)\n\n# 加载最后一个保存的模型并测试\nmodel.load_state_dict(torch.load(f'model_epoch_{10}.pth'))\nmodel.to(device)\ntest_model(model, test_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T07:59:12.718088Z","iopub.execute_input":"2024-04-28T07:59:12.718932Z","iopub.status.idle":"2024-04-28T07:59:21.484722Z","shell.execute_reply.started":"2024-04-28T07:59:12.718902Z","shell.execute_reply":"2024-04-28T07:59:21.483807Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy of the model on the test images: 98.68766404199475%\n","output_type":"stream"}]}]}